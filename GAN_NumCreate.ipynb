{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import gzip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "def load_data(data_file):\n",
    "    files = ['train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n",
    "    paths = []\n",
    "    for fileName in files:\n",
    "        paths.append(os.path.join(data_file, fileName))\n",
    "        \n",
    "    # 读取每个文件夹的数据    \n",
    "    with gzip.open(paths[0], 'rb') as train_labels_path:   # rb 以2进制格式打开\n",
    "        train_labels = np.frombuffer(train_labels_path.read(), np.uint8, offset=8)\n",
    "      \n",
    "    with gzip.open(paths[1], 'rb') as train_images_path:\n",
    "        train_images = np.frombuffer(train_images_path.read(), np.uint8, offset=16).reshape(len(train_labels), 784)\n",
    "       \n",
    "    with gzip.open(paths[2], 'rb') as test_labels_path:\n",
    "        test_labels = np.frombuffer(test_labels_path.read(), np.uint8, offset=8)\n",
    "        \n",
    "    with gzip.open(paths[3], 'rb') as test_images_path:\n",
    "        test_images = np.frombuffer(test_images_path.read(), np.uint8, offset=16).reshape(len(test_labels), 784)\n",
    "        \n",
    "    return train_labels,train_images,test_labels,test_images\n",
    " \n",
    "train_labels,train_images,test_labels,test_images = load_data('C:\\\\Users\\\\Fan\\\\JupyterFile\\\\data\\\\MNIST\\\\raw\\\\')\n",
    "print(train_labels.shape)\n",
    "print(train_images.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_images.shape)\n",
    "\n",
    "# 创建加载器\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(28,28)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        #label = 1 if self.labels[idx] >=5 else 0\n",
    "        return image,label\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_dataset = ImageDataset(images = train_images, labels = train_labels, transform = transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = ImageDataset(images = test_images, labels = test_labels, transform = transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(tensor):\n",
    "    tensor=torch.clamp(tensor,0,1)\n",
    "    tensor = tensor.detach().squeeze().numpy()\n",
    "    plt.imshow(tensor)\n",
    "    plt.axis('off')  # 关闭坐标轴\n",
    "    plt.show()\n",
    "def show_images_all(imgs):\n",
    "    n = imgs.size(0)  # 获取图片数量\n",
    "    rows = int(np.sqrt(n))  # 确定方形图中行数和列数\n",
    "    cols = n // rows\n",
    "    \n",
    "    # 创建一个新的图像\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(8, 8))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i in range(n):\n",
    "        img = imgs[i].detach().numpy()\n",
    "        axs[i].imshow(img, cmap='gray')\n",
    "        axs[i].axis('off')  # 关闭坐标轴\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型定义\n",
    "# 初始化权重函数\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:   # 没有则返回-1，有则返回0\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)    # 使用正态分布初始化权重数据，均值0，标准差0.02\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)    # 使用正态分布初始化权重数据，均值1，标准差0.02\n",
    "        nn.init.constant_(m.bias.data, 0)     # 使用常数初始化偏置项数据\n",
    "        \n",
    "# 生成器\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(100,256)\n",
    "        self.fc2 = nn.Linear(256,512)\n",
    "        self.fc3 = nn.Linear(512,1024)\n",
    "        self.fc4 = nn.Linear(1024,784)\n",
    "        self.drop = nn.Dropout2d(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.leaky_relu(self.fc1(x))\n",
    "        x = nn.functional.leaky_relu(self.fc2(x))\n",
    "        x = nn.functional.leaky_relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = torch.tanh(x)\n",
    "        \n",
    "        return x.view(-1,28,28)\n",
    "\n",
    "# 判别器\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(784,1024)\n",
    "        self.fc2 = nn.Linear(1024,512)\n",
    "        self.fc3 = nn.Linear(512,256)\n",
    "        self.fc4 = nn.Linear(256,1)\n",
    "        self.drop = nn.Dropout2d(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = nn.functional.leaky_relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = nn.functional.leaky_relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        x = nn.functional.leaky_relu(self.fc3(x))\n",
    "        x = self.drop(x)\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建生成器和鉴别器\n",
    "netG = Generator()\n",
    "netD = Discriminator()\n",
    "\n",
    "# 应用权重初始化\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "manual_seed = 886\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "beta1 = 0.5\n",
    "lr = 0.0002\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss()     # 无法使用？\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr)\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=lr)\n",
    "\n",
    "DLoss=[]\n",
    "GLoss=[]\n",
    "# 模型训练\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_images,_) in enumerate(train_loader):\n",
    "        train_size = real_images.shape[0]\n",
    "        real_labels = torch.ones(train_size, 1)\n",
    "        fake_labels = torch.zeros(train_size, 1)\n",
    "        # 生成假图\n",
    "        z = torch.randn(train_size, 100)\n",
    "        fake_images = netG(z)\n",
    "        # 更新鉴别器D\n",
    "        netD.zero_grad()\n",
    "        d_real = netD(real_images)\n",
    "        d_real_loss = criterion(d_real, real_labels)\n",
    "\n",
    "        d_fake = netD(fake_images)\n",
    "        d_fake_loss = criterion(d_fake, fake_labels)\n",
    "        d_real_loss.backward()\n",
    "        d_fake_loss.backward()\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        optimizerD.step()\n",
    "        DLoss.append(d_loss)\n",
    "        \n",
    "        # 更新生成器G\n",
    "        netG.zero_grad()\n",
    "        fake_images = netG(z)\n",
    "        d_fake = netD(fake_images)\n",
    "        g_loss = criterion(d_fake, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "        GLoss.append(g_loss)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"[Epoch {epoch+1}/{epochs}] [Batch {i}/{len(train_loader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
    "            show_images_all(fake_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(DLoss, label='D Loss')\n",
    "plt.plot(GLoss, label='G Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
